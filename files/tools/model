#!/usr/bin/python3
# -*- coding: UTF-8 -*-
from pbox import *
from tinyscript import *


__author__      = "Alexandre D'Hondt"
__email__       = "alexandre.dhondt@gmail.com"
__version__     = "1.0.0"
__copyright__   = ("A. D'Hondt", 2021)
__license__     = "gpl-3.0"
__doc__         = """
This utility aims to train Machine Learning models based on an input dataset. It currently supports various algorithms
 and allows to select a data scaler. Moreover, it supports Grid Search cross-validation for some algorithms.
"""
__description__ = "Train Machine Learning models"
__examples__    = [
    "list",
    "train dataset -a MNB",
]


def at_interrupt():
    """ Interrupt handler """
    logger.warn("Interrupted by the user.")


def __add_name(parser, optional=False, force=False):
    def model_exists(string):
        if string:
            p = config['workspace'].joinpath("models", string)
            (ts.folder_exists_or_create if force else ts.folder_exists)(str(p))
            if not force:
                Model.validate(p)
            return p
    a = ("-n", "--name", ) if optional else ("name", )
    kw = {'type': model_exists, 'help': "name of the model"}
    parser.add_argument(*a, **kw)
    return parser


def __dataset_exists(string):
    p = config['datasets'].joinpath(string)
    if Dataset.check(p):
        return Dataset(p)
    if FilelessDataset.check(p):
        return FilelessDataset(p)
    raise ValueError("Bad dataset")


if __name__ == '__main__':
    sparsers = parser.add_subparsers(dest="command", help="command to be executed")
    listm = sparsers.add_parser("list", help="list all the models from the workspace")
    listm.add_argument("--algorithms", action="store_true", help="show available algorithms instead of models")
    __add_name(sparsers.add_parser("remove", help="remove the selected model"))
    rename = sparsers.add_parser("rename", help="rename the selected model")
    __add_name(rename)
    rename.add_argument("name2", type=ts.folder_does_not_exist, help="new name of the model")
    __add_name(sparsers.add_parser("show", help="get an overview of the model"))
    test = sparsers.add_parser("test", help="test the model on a given input")
    __add_name(test)
    test.add_argument("executable", help="executable or folder containing executables or dataset")
    train = sparsers.add_parser("train", help="train a model on the given dataset")
    train.add_argument("dataset", type=__dataset_exists, help="dataset for training the model")
    __add_name(train, True)
    train.add_argument("-a", "--algorithm", choices=[a.name for a in Algorithm.registry], default="dt",
                       help="machine learning algorithm to be used\n- %s\n * supports Grid Search cross-validation\n" %\
                            "\n- ".join("%s: %s%s" % (a.name.ljust(4), a.description, ["", "*"][a.parameters.get('cv') \
                            is not None]) for a in Algorithm.registry))
    train.add_argument("-m", "--multiclass", action="store_true", help="train the model using multiple label classes")
    train.add_argument("-p", "--param", type=lambda x: x.split(","),
                       help="comma-separated list of parameters for the algorithm",
                       note="fixing a parameter with this option disables it in the cross-validation")
    train.add_argument("-s", "--scaler", choices=SCALERS.keys(),
                       help="scaler for shaping the data\n- %s\n" % \
                            "\n- ".join("%s: %s" % (k.ljust(10), "none" if v is None else v.__name__ \
                                        if not isinstance(v, tuple) else "%s with %s" % \
                                        (v[0].__name__, ", ".join("{}={}".format(*i) for i in v[1].items()))) \
                            for k, v in sorted(SCALERS.items(), key=lambda x: x[0] or "none") if k is not None))
    train.add_argument("--cv", default=3, help="number of Cross-Validation folds")
    tgroup = train.add_mutually_exclusive_group()
    tgroup.add_argument("--feature", action="extend", nargs="*", help="list of features to be selected")
    train.add_argument("--n-jobs", default=4, help="number of jobs to be run in parallel")
    tgroup.add_argument("--pattern", help="pattern of features to be selected")
    visualize = sparsers.add_parser("visualize", help="visualize the model")
    __add_name(visualize)
    visualize.add_argument("-e", "--export", action="store_true", help="export to PNG")
    visualize.add_argument("-o", "--output-dir", default=".", help="output directory")
    initialize(noargs_action="help")
    args.load = args.command != "list"
    getattr(Model(**vars(args)), args.command)(**vars(args))

