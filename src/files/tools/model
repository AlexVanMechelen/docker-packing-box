#!/usr/bin/python3
# -*- coding: UTF-8 -*-
from pbox import *
from tinyscript import *


__script__      = "Model manipulation tool"
__version__     = "1.3.4"
__contributors__ = [
    {'author': "SÃ©bastien Martinez", 'reason': "extended ML algorithms, metrics and visualizations to unsupervised "
                                               "learning"},
]
__doc__         = """
This utility aims to train Machine Learning models based on an input dataset. It currently supports various algorithms
 and allows to select a data scaler. Moreover, it supports Grid Search cross-validation for some algorithms.
"""
__description__ = "Train Machine Learning models"
__examples__    = [
    "list",
    "preprocess [model_name] my-dataset",
    "train my-dataset -a mnb",
    "show [model_name]",
]

check = lambda s: Model.check(s) or DumpedModel.check(s)


if __name__ == '__main__':
    sparsers = parser.add_subparsers(dest="command", metavar="CMD", title="positional argument",
                                     help="command to be executed")
    browse = add_argument(sparsers.add_parser("browse", category="read", help="browse input data (including "
                                              "predictions) based on the selected criteria"), "mdname")
    browse.add_argument("executable", nargs="?",
                        help="executable or folder containing executables or dataset or data CSV file")
    browse.add_argument("-q", "--query", help="query for filtering records to be selected",
                        note="see <https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html>")
    compare = add_argument(sparsers.add_parser("compare", category="read", help="compare the selected model with "
                                               "others"), "mdname")
    compare.add_argument("-d", "--dataset", type=open_dataset, action="extend", nargs="*",
                         help="dataset to be selected for the comparison")
    compare.add_argument("-i", "--include", action="store_true", help="include unformatted models")
    compare.add_argument("-m", "--model", type=open_model, action="extend", nargs="*",
                         help="model to be added in the comparison")
    add_argument(sparsers.add_parser("edit", category="create/modify/delete", help="edit the performance log file"),
                 "mdname", force=True)
    listm = sparsers.add_parser("list", category="read", help="list all the models from the workspace")
    listm.add_argument("--algorithms", action="store_true", help="show available algorithms instead of models")
    preproc = add_argument(sparsers.add_parser("preprocess", category="read",
                                               help="preprocess features and visualize the result"), "mdname")
    preproc.add_argument("executable", nargs="?",
                         help="executable or folder containing executables or dataset or data CSV file")
    preproc.add_argument("-f", "--features-set", metavar="YAML", type=ts.file_exists, default=config['features'],
                         help="features set's YAML definition", note="similar to 'dataset browse', except that it "
                         "requires a model to apply its preprocessors in addition")
    add_argument(sparsers.add_parser("purge", category="create/modify/delete",
                                     help="purge the selected model"), "mdname", force=True)
    rename = add_argument(sparsers.add_parser("rename", category="create/modify/delete",
                                              help="rename the selected model"), "mdname")
    rename.add_argument("name2", type=ts.folder_does_not_exist, help="new name of the model")
    add_argument(sparsers.add_parser("show", category="read", help="get an overview of the model"), "mdname")
    test = add_argument(sparsers.add_parser("test", category="read", help="test the model on a given input"), "mdname")
    test.add_argument("executable", help="executable or folder containing executables or dataset or data CSV file")
    test.add_argument("-f", "--features-set", metavar="YAML", type=ts.file_exists, default=config['features'],
                      help="features set's YAML definition")
    test.add_argument("--ignore-labels", action="store_true",
                      help="while computing metrics, only consider those not requiring labels")
    test.add_argument("--sep", default=",", choices=",;|\t", help="set the CSV separator",
                      note="required when using input CSV data instead of a Dataset (no effect otherwise)")
    train = sparsers.add_parser("train", category="create/modify/delete", help="train a model on the given dataset")
    train.add_argument("dataset", type=open_dataset, help="dataset for training the model")
    add_argument(train, "mdname", force=True)
    train.add_argument("-a", "--algorithm", choices=[a.name for a in Algorithm.registry], default="dt", metavar="ALGO",
                       help="machine learning algorithm to be used\n- %s\n * supports Grid Search cross-validation\n" %\
                            "\n- ".join("%s: %s%s" % (a.name.ljust(8), a.description, ["", "*"][a.parameters.get('cv') \
                            is not None]) for a in Algorithm.registry))
    train.add_argument("--algorithms-set", metavar="YAML", type=ts.file_exists, default=config['algorithms'],
                       help="algorithms set's YAML definition")
    train.add_argument("-f", "--features-set", metavar="YAML", type=ts.file_exists, default=config['features'],
                       help="features set's YAML definition")
    train.add_argument("-m", "--multiclass", action="store_true", help="train the model using multiple label classes")
    train.add_argument("-r", "--reset", action="store_true", help="reset the model before (re)training")
    train.add_argument("--cv", default=5, type=ts.pos_int, help="number of Cross-Validation folds")
    train.add_argument("--feature", action="extend", nargs="*", help="list of features to be selected")
    train.add_argument("--ignore-labels", action="store_true",
                       help="while computing metrics, only consider those not requiring labels")
    train.add_argument("--n-jobs", help="number of jobs to be run in parallel")
    train.add_argument("-p", "--param", nargs="*", help="comma-separated list of parameters for the algorithm",
                       note="fixing a parameter with this option disables it from the cross-validation")
    visualize = add_argument(sparsers.add_parser("visualize", category="read", help="visualize the model"), "mdname")
    visualize.add_argument("-e", "--export", action="store_true", help="export to PNG")
    visualize.add_argument("-o", "--output-dir", metavar="DIR", default=".", help="output directory")
    viz_dependent = visualize.add_argument_group("options depending on the chosen algorithm", before="extra arguments")
    viz_dependent.add_argument("--imputer-strategy", default="mean", choices=("constant", "mean", "most_frequent"),
                               help="strategy for imputing missing values")
    viz_dependent.add_argument("-a", "--reduction-algorithm", default="PCA", choices=("ICA", "PCA"),
                               help="dimensionality reduction algorithm")
    viz_dependent.add_argument("-d", "--distance-threshold", default=15, type=int,
                               help="distance threshold for dendrograms colors")
    viz_dependent.add_argument("-f", "--features", nargs="*",type=lambda x: x.split(","),
                               help="comma separated list of features to be selected", default="")
    viz_dependent.add_argument("-l", "--hierarchy_levels", metavar="H", default=4, type=int,
                               help="number of levels to display when truncating dendrogram")
    viz_dependent.add_argument("-n", "--n-components", metavar="N", default=20, type=int,
                               help="number of components for dimensionality reduction")
    viz_dependent.add_argument("-p", "--perplexity", metavar="P", default=30, type=int,
                               help="t-SNE perplexity for dimensionality reduction")
    viz_dependent.add_argument("-r", "--reduce-train-data", action="store_true", help="reduce the training data",
                               note="the data is only reduced for the visualization by default")
    viz_dependent.add_argument("-t", "--plot-labels", action="store_true", help="plot true labels of packers")
    viz_dependent.add_argument("--multiclass", action="store_true", help="plot multiclass true labels of packers")
    viz_dependent.add_argument("--plot-extensions", action="store_true", help="plot the file extensions")
    viz_dependent.add_argument("--plot-formats", action="store_true", help="plot the file formats")
    viz_dependent.add_argument('--range', type=float, nargs=4,
                               help='select range values to plot in format: x_min x_max y_min y_max')
    initialize(noargs_action="usage", autocomplete=True)
    logger.name = "model"
    logging.configLogger(logger, ["INFO", "DEBUG"][args.verbose], fmt=LOG_FORMATS[args.verbose], relative=True)
    # prepare parsed arguments
    name = getattr(args, "name", None)
    args.load = name is not None and args.command not in ["list", "purge"]
    set_yaml(args)
    # now execute
    if args.command == "purge":
        if not purge_items(Model, name):
            logger.warning("No model to purge in workspace (%s)" % str(config['models']) if name == "all" else \
                           "No model matched the given name")
    elif args.command == "list":
        Model(**vars(args)).list()
    elif name == "all":
        logger.warning("Model cannot be named 'all' (reserved word)")
    else:
        if args.command == "train":
            args.param = expand_parameters(*(args.param or []))
        if args.command == "visualize":
            args.viz_params = {}
            for a in ["distance_threshold", "features", "hierarchy_levels", "imputer_strategy", "multiclass",
                      "n_components", "perplexity", "plot_extensions", "plot_formats", "plot_labels", "range",
                      "reduce_train_data", "reduction_algorithm"]:
                args.viz_params[a] = getattr(args, a)
                delattr(args, a)
        getattr(Model(**vars(args)), args.command)(**vars(args))

