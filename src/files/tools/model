#!/usr/bin/python3
# -*- coding: UTF-8 -*-
from pbox import *
from tinyscript import *


__author__      = "Alexandre D'Hondt"
__email__       = "alexandre.dhondt@gmail.com"
__version__     = "1.0.0"
__copyright__   = ("A. D'Hondt", 2021)
__license__     = "gpl-3.0"
__doc__         = """
This utility aims to train Machine Learning models based on an input dataset. It currently supports various algorithms
 and allows to select a data scaler. Moreover, it supports Grid Search cross-validation for some algorithms.
"""
__description__ = "Train Machine Learning models"
__examples__    = [
    "list",
    "train dataset -a MNB",
]


def at_interrupt():
    """ Interrupt handler """
    logger.warn("Interrupted by the user.")


def __add_name(parser, optional=False, force=False, joblib=False):
    def model_exists(string):
        if string:
            p = ts.Path(string)
            if joblib and p.is_file() and p.extension == ".joblib":
                return p
            p = config['workspace'].joinpath("models", string)
            (ts.folder_exists_or_create if force else ts.folder_exists)(str(p))
            if not force:
                Model.validate(p)
            return p
    a = ("-n", "--name", ) if optional else ("name", )
    kw = {'type': model_exists, 'help': "name of the model"}
    parser.add_argument(*a, **kw)
    return parser


def __dataset_exists(string):
    p = config['datasets'].joinpath(string)
    if Dataset.check(p):
        return Dataset(p)
    if FilelessDataset.check(p):
        return FilelessDataset(p)
    raise ValueError("Bad dataset")


def __valid_model(s):
    try:
        DumpedModel(s)
        return s
    except (KeyError, OSError):
        Model(s)
        return s


if __name__ == '__main__':
    pp_help = "preprocessor for shaping the data\n- %s\n" % \
              "\n- ".join("%s: %s" % (k.ljust(10), "none" if v is None else v.__name__ \
              if not isinstance(v, tuple) else "%s with %s" % \
              (v[0].__name__, ", ".join("{}={}".format(*i) for i in v[1].items()))) \
              for k, v in sorted(PREPROCESSORS.items(), key=lambda x: x[0] or "none") if k is not None)
    sparsers = parser.add_subparsers(dest="command", help="command to be executed")
    compare = __add_name(sparsers.add_parser("compare", help="compare the selected model with others"), True)
    compare.add_argument("-d", "--dataset", type=__dataset_exists, action="extend", nargs="*",
                         help="dataset to be selected for the comparison")
    compare.add_argument("-i", "--include", action="store_true", help="include unformatted models")
    compare.add_argument("-m", "--model", type=__valid_model, action="extend", nargs="*",
                         help="model to be added in the comparison")
    __add_name(sparsers.add_parser("edit", help="edit the performance log file"), True)
    listm = sparsers.add_parser("list", help="list all the models from the workspace")
    listm.add_argument("--algorithms", action="store_true", help="show available algorithms instead of models")
    __add_name(sparsers.add_parser("purge", help="purge the selected model"), force=True)
    rename = sparsers.add_parser("rename", help="rename the selected model")
    __add_name(rename)
    rename.add_argument("name2", type=ts.folder_does_not_exist, help="new name of the model")
    __add_name(sparsers.add_parser("show", help="get an overview of the model"))
    test = sparsers.add_parser("test", help="test the model on a given input")
    __add_name(test, joblib=True)
    test.add_argument("executable", help="executable or folder containing executables or dataset or data CSV file")
    tgroup1 = test.add_mutually_exclusive_group()
    test.add_argument("-m", "--multiclass", action="store_true", help="test the model using multiple label classes")
    test.add_argument("-p", "--preprocessor", action="extend", nargs="*", choices=PREPROCESSORS.keys(), help=pp_help)
    tgroup1.add_argument("--feature", action="extend", nargs="*", help="list of features to be selected")
    tgroup1.add_argument("--pattern", help="pattern of features to be selected")
    test.add_argument("--sep", default=",", choices=",;|\t", help="set the CSV separtor")
    train = sparsers.add_parser("train", help="train a model on the given dataset")
    train.add_argument("dataset", type=__dataset_exists, help="dataset for training the model")
    __add_name(train, True)
    train.add_argument("-a", "--algorithm", choices=[a.name for a in Algorithm.registry], default="dt",
                       help="machine learning algorithm to be used\n- %s\n * supports Grid Search cross-validation\n" %\
                            "\n- ".join("%s: %s%s" % (a.name.ljust(4), a.description, ["", "*"][a.parameters.get('cv') \
                            is not None]) for a in Algorithm.registry))
    train.add_argument("-m", "--multiclass", action="store_true", help="train the model using multiple label classes")
    train.add_argument("-p", "--preprocessor", action="extend", nargs="*", choices=PREPROCESSORS.keys(), help=pp_help)
    train.add_argument("-r", "--reset", action="store_true", help="reset the model before (re)training")
    train.add_argument("--cv", default=3, help="number of Cross-Validation folds")
    tgroup2 = train.add_mutually_exclusive_group()
    tgroup2.add_argument("--feature", action="extend", nargs="*", help="list of features to be selected")
    train.add_argument("--n-jobs", default=N_JOBS, help="number of jobs to be run in parallel")
    train.add_argument("--param", action="extend", nargs="*", type=lambda x: x.split(","),
                       help="comma-separated list of parameters for the algorithm",
                       note="fixing a parameter with this option disables it from the cross-validation")
    tgroup2.add_argument("--pattern", help="pattern of features to be selected")
    visualize = sparsers.add_parser("visualize", help="visualize the model")
    __add_name(visualize)
    visualize.add_argument("-e", "--export", action="store_true", help="export to PNG")
    visualize.add_argument("-o", "--output-dir", default=".", help="output directory")
    initialize(noargs_action="help")
    logger.name = "model"
    logging.configLogger(logger, ["INFO", "DEBUG"][args.verbose], fmt=LOG_FORMATS[args.verbose], relative=True)
    args.load = args.command != "list"
    try:
        m = DumpedModel(**vars(args))
    except (KeyError, OSError):
        m = Model(**vars(args))
    getattr(m, args.command)(**vars(args))

