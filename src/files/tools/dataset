#!/usr/bin/python3
# PYTHON_ARGCOMPLETE_OK
# -*- coding: UTF-8 -*-
from pbox import *
from tinyscript import *


__script__       = "Dataset manipulation tool"
__version__      = "2.6.4"
__contributors__ = [
    {'author': "Romain Jennes", 'reason': "added dataset alterations and adversarial learning capabilities"},
]
__doc__         = """
This tool aims to manipulate a dataset in many ways including its creation, enlargement, update, alteration, selection,
 merging, export or purge.
"""
__description__ = "Make datasets of packed and not packed executables for use with Machine Learning"
__examples__    = [
    "alter my-dataset --packed-only",
    "alter my-dataset --percentage 30",
    "alter my-dataset --query \"label == '-'\"",
    "browse my-dataset --query \"label == 'upx'\"",
    "convert my-dataset --new-name my-fileless-dataset",
    "export my-dataset --format packed-samples --output my-dataset-files -n 100",
    "fix my-dataset --detect",
    "fix my-dataset --labels my-labels.json",
    "ingest dataset-packed-elf --detect",
    "ingest dataset-packed-pe --labels /path/to/exe/labels.json --merge --rename as-is",
    "list --show-all",
    "make my-dataset -f ELF -n 500 --source-dir /path/to/dotnet/exe",
    "make my-dataset -f PE,ELF -n 2000",
    "merge my-dataset dataset-to-be-merged",
    "plot features my-dataset byte_0_after_ep byte_1_after_ep",
    "plot features my-dataset number_resources --format png",
    "plot labels my-dataset",
    "preprocess my-dataset --preprocessor Std",
    "purge all",
    "purge test-*",
    "remove my-dataset --query \"label == 'aspack'\"",
    "select my-dataset my-new-dataset --query \"label == 'upx'\"",
    "show my-dataset --per-format --limit 20",
    "update my-dataset --detect --refresh -s /path1/to/exe -s /path2/to/exe",
    "update my-dataset --source-dir /path/to/exe --labels /path/to/exe/labels.json",
    "view my-dataset --query \"ctime > 2020\"",
    "view my-dataset -q \"'PE32' in format\"",
]

check = lambda s: Dataset.check(s) or FilelessDataset.check(s)


def _feature_identifier(name):
    Features(None)
    if name not in Features.names():
        raise ValueError
    return name


if __name__ == '__main__':
    pp_help = "preprocessor for shaping the data\n- %s\n" % \
              "\n- ".join("%s: %s" % (k.ljust(10), "none" if v is None else v.__name__ \
              if not isinstance(v, tuple) else "%s with %s" % \
              (v[0].__name__, ", ".join("{}={}".format(*i) for i in v[1].items()))) \
              for k, v in sorted(PREPROCESSORS.items(), key=lambda x: x[0] or "none") if k is not None)
    cmds = parser.add_subparsers(dest="command", metavar="CMD", title="positional argument",
                                 help="command to be executed")
    alter = add_argument(cmds.add_parser("alter", category="create/modify/delete",
                                         help="alter the target dataset with a set of transformations"), "dsname")
    alter.add_argument("-a", "--alterations-set", metavar="YAML", default=str(config['alterations']),
                       type=ts.file_exists, help="alterations set's YAML definition")
    alter.add_argument("-n", "--new-name", help="name for the new altered dataset",
                       note="if None, the original dataset is altered")
    agroup = alter.add_mutually_exclusive_group()
    agroup.add_argument("-p", "--percentage", type=percentage, help="percentage of samples to be altered")
    add_argument(agroup, "query", default=None)
    agroup.add_argument("--packed-only", action="store_true", help="alter packed samples only")
    browse = add_argument(cmds.add_parser("browse", category="read",
                                          help="compute features and browse the resulting data"), "dsname")
    bgroup = browse.add_mutually_exclusive_group()
    bgroup.add_argument("-f", "--features-set", metavar="YAML", type=ts.file_exists, default=str(config['features']),
                        help="features set's YAML definition")
    bgroup.add_argument("-n", "--no-feature", action="store_true", help="do not compute features")
    add_argument(browse, "query")
    convert = add_argument(cmds.add_parser("convert", category="create/modify/delete",
                                           help="convert the target dataset to a fileless one"), "dsname")
    convert.add_argument("-f", "--features-set", metavar="YAML", type=ts.file_exists, default=str(config['features']),
                         help="features set's YAML definition")
    convert.add_argument("-n", "--new-name", help="name for the new converted dataset",
                         note="if None, the original dataset is overwritten")
    add_argument(cmds.add_parser("edit", category="create/modify/delete", help="edit the data file"), "dsname")
    export = add_argument(cmds.add_parser("export", category="create/modify/delete", help="export packed samples from a"
                                          " dataset or export the dataset to a given format"), "dsname")
    export.add_argument("-f", "--format", default="dsff", choices=("arff", "csv", "dsff", "packed-samples"),
                        help="output format")
    export.add_argument("-o", "--output", default="export", metavar="F", type=ts.folder_does_not_exist,
                        help="output folder or file for the export", note="the extension gets added automatically")
    export_ = export.add_argument_group("option when exporting packed samples", before="extra arguments")
    export_.add_argument("-n", "--number-samples", dest="n", type=ts.pos_int, default=0,
                         help="number of packed samples to be exported")
    fix = add_argument(cmds.add_parser("fix", category="create/modify/delete", help="fix a corrupted dataset"),
                       "dsname")
    fgroup = fix.add_mutually_exclusive_group()
    fgroup.add_argument("-d", "--detect", action="store_true", help="detect used packer with installed detectors")
    fgroup.add_argument("-l", "--labels", type=ts.json_config, help="set labels from a JSON file")
    ingest = cmds.add_parser("ingest", category="create/modify/delete",
                             help="ingest samples from a folder into new dataset(s)")
    ingest.add_argument("folder", type=ts.folder_exists, help="target folder with subfolders containing samples")
    igroup = ingest.add_mutually_exclusive_group()
    igroup.add_argument("-d", "--detect", action="store_true", help="detect used packer with installed detectors")
    igroup.add_argument("-l", "--labels", type=ts.json_config, help="set labels from a JSON file")
    ingest.add_argument("--merge", action="store_true", help="merge all subfolders into a single dataset")
    ingest.add_argument("-m", "--min-samples", type=ts.pos_int, default=100,
                        help="minimum of samples to be found in subfolders for being kept")
    ingest.add_argument("-M", "--max-samples", type=ts.pos_int, default=0,
                        help="maximum of samples to be found in subfolders for being kept")
    ingest.add_argument("-p", "--prefix", default="", help="prefix to be added to the name(s) of the new dataset(s)")
    ingest.add_argument("-r", "--rename", default="slugify", choices=tuple(RENAME_FUNCTIONS.keys()),
                        help="apply a function for naming the new dataset(s)")
    ingest.add_argument("-x", "--exclude", nargs="*", help="folder to be excluded")
    listds = cmds.add_parser("list", category="read", help="list all the datasets from the workspace")
    listds.add_argument("-a", "--show-all", action="store_true", help="show all datasets even those that are corrupted")
    listds.add_argument("-f", "--hide-files", action="store_true", help="hide the 'files' column")
    listds.add_argument("-r", "--raw", action="store_true", help="display unformatted text", note="useful with grep")
    make = add_argument(cmds.add_parser("make", category="create/modify/delete", help="add n randomly chosen "
                                        "executables from input sources to the dataset"), "dsname", force=True)
    make_ = make.add_mutually_exclusive_group()
    make_.add_argument("-a", "--pack-all", action="store_true", help="pack all executables",
                       note="this cannot be set with -b/--balance")
    make_.add_argument("-b", "--balance", action="store_true", help="balance the dataset relatively to the number of "
                                                                    "packers used, not between packed and not packed")
    make.add_argument("-f", "--formats", type=ts.values_list, default="All", help="list of formats to be considered")
    make.add_argument("-n", "--number", dest="n", type=ts.pos_int, default=100,
                      help="number of executables for the output dataset")
    make.add_argument("-p", "--packer", action="extend", nargs="*", type=lambda p: Packer.get(p),
                      help="packer to be used")
    make.add_argument("-s", "--source-dir", action="extend", nargs="*", type=lambda p: ts.Path(p, expand=True),
                      help="executables source directory to be included")
    merge = add_argument(cmds.add_parser("merge", category="create/modify/delete", help="merge two datasets"), "dsname")
    add_argument(merge, "dsname", argname="name2", help="name of the dataset to merge")
    merge.add_argument("-n", "--new-name", help="name for the new merged dataset",
                       note="if None, the original dataset is overwritten")
    plot = cmds.add_parser("plot", category="read", help="plot something about the dataset")
    pcmds = plot.add_subparsers(dest="subcommand", help="command to be executed")
    plot_feat = add_argument(pcmds.add_parser("features", help="distribution of a given feature or multiple features "
                                                               "combined (bar chart)"), "dsname")
    plot_feat.add_argument("feature", action="extend", nargs="*", type=_feature_identifier, help="feature identifiers")
    add_argument(plot_feat, "format")
    plot_feat.add_argument("-m", "--multiclass", action="store_true",
                           help="process features using multiple label classes")
    plot_featcomp = add_argument(pcmds.add_parser("features-compare", help="compare feature difference between this "
                                                                           "dataset and others"), "dsname")
    plot_featcomp.add_argument("feature", action="extend", nargs="*", type=_feature_identifier,
                               help="feature identifiers")
    plot_featcomp.add_argument("-a", "--aggregate", help="Pattern to aggregate some of the features together",
                               default="byte_[0-9]+_after_ep")
    plot_featcomp.add_argument("-d", "--datasets", action="extend", nargs="*", help="datasets to compare features to",
                               required=True)
    add_argument(plot_featcomp, "format")
    plot_featcomp.add_argument("-n", "--max-features", type=ts.pos_int, help="plot n features with largest difference")
    plot_ig = add_argument(pcmds.add_parser("infogain", help="sorted distribution of information gains for the selected "
                                                             "features (bar chart)"), "dsname")
    plot_ig.add_argument("feature", action="extend", nargs="*", help="feature identifiers")
    add_argument(plot_ig, "format")
    plot_ig.add_argument("-m", "--multiclass", action="store_true", help="use multiple label classes")
    plot_ig.add_argument("-n", "--max-features", type=ts.pos_int, help="plot n features with highest information gain")
    plot_igcomp = add_argument(pcmds.add_parser("infogain-compare", help="compare information gain difference between "
                                                                         "this dataset and others"), "dsname")
    plot_igcomp.add_argument("feature", action="extend", nargs="*", type=_feature_identifier, help="feature identifiers")
    plot_igcomp.add_argument("-a", "--aggregate", help="Pattern to aggregate some of the features together",
                             default="byte_[0-9]+_after_ep")
    plot_igcomp.add_argument("-d", "--datasets", action="extend", nargs="*", help="datasets to compare features to",
                             required=True)
    add_argument(plot_igcomp, "format")
    plot_igcomp.add_argument("-n", "--max-features", type=ts.pos_int,
                             help="plot n features with highest information gain")
    plot_igcomp.add_argument("-m", "--multiclass", action="store_true", help="use multiple label classes")
    plot_lab = add_argument(pcmds.add_parser("labels", help="distribution of labels in the dataset (pie chart)"),
                            "dsname")
    add_argument(plot_lab, "format")
    plot_samp = add_argument(pcmds.add_parser("samples", help="plot each executable from the target dataset"), "dsname")
    add_argument(plot_samp, "format")
    preproc = add_argument(cmds.add_parser("preprocess", category="read",
                                           help="preprocess the input dataset given preprocessors"), "dsname")
    preproc.add_argument("-p", "--preprocessor", action="extend", nargs="*", choices=PREPROCESSORS.keys(), help=pp_help)
    add_argument(preproc, "query")
    purge = add_argument(cmds.add_parser("purge", category="create/modify/delete", help="purge a dataset"), "dsname",
                         force=True, note="use 'all' to purge all datasets or '*' to select a part of them")
    purge.add_argument("-b", "--backup", action="store_true", help="only purge backups")
    remove = add_argument(cmds.add_parser("remove", category="create/modify/delete",
                                          help="remove executables from a dataset"), "dsname")
    add_argument(remove, "query")
    rename = add_argument(cmds.add_parser("rename", category="create/modify/delete", help="rename a dataset"), "dsname")
    rename.add_argument("name2", type=ts.folder_does_not_exist, help="new name of the dataset")
    add_argument(cmds.add_parser("revert", category="create/modify/delete",
                                 help="revert a dataset to its previous state"), "dsname")
    select = add_argument(cmds.add_parser("select", category="create/modify/delete",
                                          help="select a subset of the dataset"), "dsname")
    select.add_argument("name2", type=ts.folder_does_not_exist, help="name of the new dataset")
    select.add_argument("-n", "--number", dest="limit", type=ts.pos_int, default=0,
                        help="limit number of executables for the output dataset", note="0 means all")
    add_argument(select, "query")
    show = add_argument(cmds.add_parser("show", category="read", help="get an overview of the dataset"), "dsname")
    show.add_argument("-l", "--limit", default=10, type=int, help="number of executables to be displayed per format")
    show.add_argument("--per-format", action="store_true", help="display statistics per format")
    update = add_argument(cmds.add_parser("update", category="create/modify/delete",
                                          help="update a dataset with new executables"), "dsname", force=True)
    ugroup = update.add_mutually_exclusive_group()
    ugroup.add_argument("-d", "--detect", action="store_true", help="detect used packer with installed detectors")
    ugroup.add_argument("-l", "--labels", type=ts.json_config, help="set labels from a JSON file")
    update.add_argument("-n", "--number", dest="n", type=ts.pos_int, default=0,
                        help="number of executables for the output dataset", note="0 means all")
    update.add_argument("-r", "--refresh", action="store_true", help="refresh labels of already existing executables")
    update.add_argument("-s", "--source-dir", action="extend", nargs="*", type=lambda p: ts.Path(p, expand=True),
                        help="executables source directory to be included")
    add_argument(add_argument(cmds.add_parser("view", category="read", help="view executables filtered from a dataset"),
                              "dsname"), "query")
    initialize(noargs_action="usage")
    configure_logging(args.verbose)
    if args.command == "plot" and args.subcommand == "features" and len(args.feature) == 0:
        logger.warning("No feature selected")
        sys.exit(0)
    # prepare parsed arguments
    name = getattr(args, "name", None)
    args.load = name is not None and args.command not in ["ingest", "list", "purge"]
    set_yaml(args)
    # now execute
    if args.command == "purge":
        if not Dataset.purge(name):
            logger.warning("No dataset to purge in workspace (%s)" % str(config['datasets']) if name == "all" else \
                           "No dataset matched the given name")
    elif args.command == "list":
        FilelessDataset(**vars(args)).list(**vars(args))
    elif name == "all":
        logger.warning("Dataset cannot be named 'all' (reserved word)")
    elif name is not None:
        try:
            ds = Dataset.load(name)
        except ValueError:
            args.name_check = True
            ds = Dataset(**vars(args))
        getattr(ds, args.command)(**vars(args))
        # it may occur that packing fails with a silenced error and that the related executable file remains in the
        #  files subfolder of the dataset while not handled in data.csv, hence creating an inconsistency ;
        #  fixing the dataset right after the make command allows to avoid this inconsistency
        if args.command == "make":
            ds.fix()
    else:
        if args.command == "ingest":
            args.rename_func = RENAME_FUNCTIONS[args.rename]
        getattr(Dataset(**vars(args)), args.command)(**vars(args))

